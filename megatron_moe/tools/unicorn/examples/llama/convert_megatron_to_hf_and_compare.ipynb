{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec7dc72d-b7d9-4372-b1c2-66eb4a0bb17b",
   "metadata": {},
   "source": [
    "### Convert Megatron checkpoint to Huggingface model\n",
    "1. Convert the Megatron checkpoint to Huggingface Model.\n",
    "2. Compare the model weights between original huggingface model and the converted one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e94f534-c209-4cdb-9295-3e92f1064292",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-10-18 06:02:24,765] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import argparse\n",
    "\n",
    "MEGATRON_ROOT = \"/cpfs/29ccba8f16c61395/data/user/liushan/projects/Megatron-LM-master/\"\n",
    "sys.path.insert(0, MEGATRON_ROOT)\n",
    "\n",
    "# import unicorn\n",
    "sys.path.append(os.path.join(MEGATRON_ROOT, \"tools\", \"unicorn\"))\n",
    "import unicorn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71cb3114-371b-49aa-bea5-f5d6a51bb7a4",
   "metadata": {},
   "source": [
    "#### Convert Megatron checkpoint to Huggingface model\n",
    "- You can also use shell in `tools/unicorn/examples/llama/convert_megatron_to_hf.sh`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd621d1a-3533-4747-8e39-491a7bba1d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use the converted megatron checkpoint by `tests/unicorn/convert_hf_to_megatron_and_resume.ipynb`,\n",
    "\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser = unicorn.add_checkpointing_args(parser)\n",
    "    parser = unicorn.add_transformers_checkpoint_args(parser)\n",
    "    parser = unicorn.add_megatron_checkpoint_args(parser)\n",
    "    args = parser.parse_args()\n",
    "    return args\n",
    "\n",
    "megatron_ckpt = os.path.join(MEGATRON_ROOT, \"models\", \"llama-megatron\")\n",
    "\n",
    "sys.argv = ['script.py',\n",
    "            '--convert_checkpoint_from_megatron_to_transformers',\n",
    "            '--megatron-path', MEGATRON_ROOT,\n",
    "            '--load-path', os.path.join(MEGATRON_ROOT, \"models\", \"llama-megatron\", \"release\"),\n",
    "            '--save-path', os.path.join(MEGATRON_ROOT, \"models\", \"llama-hf\") ,\n",
    "            '--model-name', 'llama2-13b',\n",
    "            '--template-name', 'llama',\n",
    "            '--print-checkpoint-structure',\n",
    "            '--target_params_dtype', 'fp16']\n",
    "\n",
    "args = parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a832170b-86f9-44e5-9f9d-294b6c3921aa",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Loading Megatron-LM checkpoint from: /cpfs/29ccba8f16c61395/data/user/liushan/projects/Megatron-LM-master/models/llama-megatron/release/mp_rank_00_000/model_optim_rng.pt\n",
      "=> vocab_size: 32000\n",
      "=> Saving <class 'transformers.models.llama.configuration_llama.LlamaConfig'> to /cpfs/29ccba8f16c61395/data/user/liushan/projects/Megatron-LM-master/models/llama-hf ...\n",
      "=> converting ...\n",
      "=> converting word embeddings ...\n",
      "=> Converting transformer layers ...\n",
      "=> converting pipeline parallel rank 0 ...\n",
      "\t=> processing layers.0.input_norm.weight ...\n",
      "\t=> processing layers.0.self_attention.query_key_value.weight ...\n",
      "\t=> processing layers.0.self_attention.dense.weight ...\n",
      "\t=> processing layers.0.post_attention_norm.weight ...\n",
      "\t=> processing layers.0.mlp.dense_h_to_4h.weight ...\n",
      "\t=> processing layers.0.mlp.dense_4h_to_h.weight ...\n",
      "\t=> processing layers.1.input_norm.weight ...\n",
      "\t=> processing layers.1.self_attention.query_key_value.weight ...\n",
      "\t=> processing layers.1.self_attention.dense.weight ...\n",
      "\t=> processing layers.1.post_attention_norm.weight ...\n",
      "\t=> processing layers.1.mlp.dense_h_to_4h.weight ...\n",
      "\t=> processing layers.1.mlp.dense_4h_to_h.weight ...\n",
      "\t=> processing layers.2.input_norm.weight ...\n",
      "\t=> processing layers.2.self_attention.query_key_value.weight ...\n",
      "\t=> processing layers.2.self_attention.dense.weight ...\n",
      "\t=> processing layers.2.post_attention_norm.weight ...\n",
      "\t=> processing layers.2.mlp.dense_h_to_4h.weight ...\n",
      "\t=> processing layers.2.mlp.dense_4h_to_h.weight ...\n",
      "\t=> processing layers.3.input_norm.weight ...\n",
      "\t=> processing layers.3.self_attention.query_key_value.weight ...\n",
      "\t=> processing layers.3.self_attention.dense.weight ...\n",
      "\t=> processing layers.3.post_attention_norm.weight ...\n",
      "\t=> processing layers.3.mlp.dense_h_to_4h.weight ...\n",
      "\t=> processing layers.3.mlp.dense_4h_to_h.weight ...\n",
      "\t=> processing layers.4.input_norm.weight ...\n",
      "\t=> processing layers.4.self_attention.query_key_value.weight ...\n",
      "\t=> processing layers.4.self_attention.dense.weight ...\n",
      "\t=> processing layers.4.post_attention_norm.weight ...\n",
      "\t=> processing layers.4.mlp.dense_h_to_4h.weight ...\n",
      "\t=> processing layers.4.mlp.dense_4h_to_h.weight ...\n",
      "\t=> processing layers.5.input_norm.weight ...\n",
      "\t=> processing layers.5.self_attention.query_key_value.weight ...\n",
      "\t=> processing layers.5.self_attention.dense.weight ...\n",
      "\t=> processing layers.5.post_attention_norm.weight ...\n",
      "\t=> processing layers.5.mlp.dense_h_to_4h.weight ...\n",
      "\t=> processing layers.5.mlp.dense_4h_to_h.weight ...\n",
      "\t=> processing layers.6.input_norm.weight ...\n",
      "\t=> processing layers.6.self_attention.query_key_value.weight ...\n",
      "\t=> processing layers.6.self_attention.dense.weight ...\n",
      "\t=> processing layers.6.post_attention_norm.weight ...\n",
      "\t=> processing layers.6.mlp.dense_h_to_4h.weight ...\n",
      "\t=> processing layers.6.mlp.dense_4h_to_h.weight ...\n",
      "\t=> processing layers.7.input_norm.weight ...\n",
      "\t=> processing layers.7.self_attention.query_key_value.weight ...\n",
      "\t=> processing layers.7.self_attention.dense.weight ...\n",
      "\t=> processing layers.7.post_attention_norm.weight ...\n",
      "\t=> processing layers.7.mlp.dense_h_to_4h.weight ...\n",
      "\t=> processing layers.7.mlp.dense_4h_to_h.weight ...\n",
      "\t=> processing layers.8.input_norm.weight ...\n",
      "\t=> processing layers.8.self_attention.query_key_value.weight ...\n",
      "\t=> processing layers.8.self_attention.dense.weight ...\n",
      "\t=> processing layers.8.post_attention_norm.weight ...\n",
      "\t=> processing layers.8.mlp.dense_h_to_4h.weight ...\n",
      "\t=> processing layers.8.mlp.dense_4h_to_h.weight ...\n",
      "\t=> processing layers.9.input_norm.weight ...\n",
      "\t=> processing layers.9.self_attention.query_key_value.weight ...\n",
      "\t=> processing layers.9.self_attention.dense.weight ...\n",
      "\t=> processing layers.9.post_attention_norm.weight ...\n",
      "\t=> processing layers.9.mlp.dense_h_to_4h.weight ...\n",
      "\t=> processing layers.9.mlp.dense_4h_to_h.weight ...\n",
      "\t=> processing layers.10.input_norm.weight ...\n",
      "\t=> processing layers.10.self_attention.query_key_value.weight ...\n",
      "\t=> processing layers.10.self_attention.dense.weight ...\n",
      "\t=> processing layers.10.post_attention_norm.weight ...\n",
      "\t=> processing layers.10.mlp.dense_h_to_4h.weight ...\n",
      "\t=> processing layers.10.mlp.dense_4h_to_h.weight ...\n",
      "\t=> processing layers.11.input_norm.weight ...\n",
      "\t=> processing layers.11.self_attention.query_key_value.weight ...\n",
      "\t=> processing layers.11.self_attention.dense.weight ...\n",
      "\t=> processing layers.11.post_attention_norm.weight ...\n",
      "\t=> processing layers.11.mlp.dense_h_to_4h.weight ...\n",
      "\t=> processing layers.11.mlp.dense_4h_to_h.weight ...\n",
      "\t=> processing layers.12.input_norm.weight ...\n",
      "\t=> processing layers.12.self_attention.query_key_value.weight ...\n",
      "\t=> processing layers.12.self_attention.dense.weight ...\n",
      "\t=> processing layers.12.post_attention_norm.weight ...\n",
      "\t=> processing layers.12.mlp.dense_h_to_4h.weight ...\n",
      "\t=> processing layers.12.mlp.dense_4h_to_h.weight ...\n",
      "\t=> processing layers.13.input_norm.weight ...\n",
      "\t=> processing layers.13.self_attention.query_key_value.weight ...\n",
      "\t=> processing layers.13.self_attention.dense.weight ...\n",
      "\t=> processing layers.13.post_attention_norm.weight ...\n",
      "\t=> processing layers.13.mlp.dense_h_to_4h.weight ...\n",
      "\t=> processing layers.13.mlp.dense_4h_to_h.weight ...\n",
      "\t=> processing layers.14.input_norm.weight ...\n",
      "\t=> processing layers.14.self_attention.query_key_value.weight ...\n",
      "\t=> processing layers.14.self_attention.dense.weight ...\n",
      "\t=> processing layers.14.post_attention_norm.weight ...\n",
      "\t=> processing layers.14.mlp.dense_h_to_4h.weight ...\n",
      "\t=> processing layers.14.mlp.dense_4h_to_h.weight ...\n",
      "\t=> processing layers.15.input_norm.weight ...\n",
      "\t=> processing layers.15.self_attention.query_key_value.weight ...\n",
      "\t=> processing layers.15.self_attention.dense.weight ...\n",
      "\t=> processing layers.15.post_attention_norm.weight ...\n",
      "\t=> processing layers.15.mlp.dense_h_to_4h.weight ...\n",
      "\t=> processing layers.15.mlp.dense_4h_to_h.weight ...\n",
      "\t=> processing layers.16.input_norm.weight ...\n",
      "\t=> processing layers.16.self_attention.query_key_value.weight ...\n",
      "\t=> processing layers.16.self_attention.dense.weight ...\n",
      "\t=> processing layers.16.post_attention_norm.weight ...\n",
      "\t=> processing layers.16.mlp.dense_h_to_4h.weight ...\n",
      "\t=> processing layers.16.mlp.dense_4h_to_h.weight ...\n",
      "\t=> processing layers.17.input_norm.weight ...\n",
      "\t=> processing layers.17.self_attention.query_key_value.weight ...\n",
      "\t=> processing layers.17.self_attention.dense.weight ...\n",
      "\t=> processing layers.17.post_attention_norm.weight ...\n",
      "\t=> processing layers.17.mlp.dense_h_to_4h.weight ...\n",
      "\t=> processing layers.17.mlp.dense_4h_to_h.weight ...\n",
      "\t=> processing layers.18.input_norm.weight ...\n",
      "\t=> processing layers.18.self_attention.query_key_value.weight ...\n",
      "\t=> processing layers.18.self_attention.dense.weight ...\n",
      "\t=> processing layers.18.post_attention_norm.weight ...\n",
      "\t=> processing layers.18.mlp.dense_h_to_4h.weight ...\n",
      "\t=> processing layers.18.mlp.dense_4h_to_h.weight ...\n",
      "\t=> processing layers.19.input_norm.weight ...\n",
      "\t=> processing layers.19.self_attention.query_key_value.weight ...\n",
      "\t=> processing layers.19.self_attention.dense.weight ...\n",
      "\t=> processing layers.19.post_attention_norm.weight ...\n",
      "\t=> processing layers.19.mlp.dense_h_to_4h.weight ...\n",
      "\t=> processing layers.19.mlp.dense_4h_to_h.weight ...\n",
      "=> converting pipeline parallel rank 1 ...\n",
      "\t=> processing layers.0.input_norm.weight ...\n",
      "\t=> processing layers.0.self_attention.query_key_value.weight ...\n",
      "\t=> processing layers.0.self_attention.dense.weight ...\n",
      "\t=> processing layers.0.post_attention_norm.weight ...\n",
      "\t=> processing layers.0.mlp.dense_h_to_4h.weight ...\n",
      "\t=> processing layers.0.mlp.dense_4h_to_h.weight ...\n",
      "\t=> processing layers.1.input_norm.weight ...\n",
      "\t=> processing layers.1.self_attention.query_key_value.weight ...\n",
      "\t=> processing layers.1.self_attention.dense.weight ...\n",
      "\t=> processing layers.1.post_attention_norm.weight ...\n",
      "\t=> processing layers.1.mlp.dense_h_to_4h.weight ...\n",
      "\t=> processing layers.1.mlp.dense_4h_to_h.weight ...\n",
      "\t=> processing layers.2.input_norm.weight ...\n",
      "\t=> processing layers.2.self_attention.query_key_value.weight ...\n",
      "\t=> processing layers.2.self_attention.dense.weight ...\n",
      "\t=> processing layers.2.post_attention_norm.weight ...\n",
      "\t=> processing layers.2.mlp.dense_h_to_4h.weight ...\n",
      "\t=> processing layers.2.mlp.dense_4h_to_h.weight ...\n",
      "\t=> processing layers.3.input_norm.weight ...\n",
      "\t=> processing layers.3.self_attention.query_key_value.weight ...\n",
      "\t=> processing layers.3.self_attention.dense.weight ...\n",
      "\t=> processing layers.3.post_attention_norm.weight ...\n",
      "\t=> processing layers.3.mlp.dense_h_to_4h.weight ...\n",
      "\t=> processing layers.3.mlp.dense_4h_to_h.weight ...\n",
      "\t=> processing layers.4.input_norm.weight ...\n",
      "\t=> processing layers.4.self_attention.query_key_value.weight ...\n",
      "\t=> processing layers.4.self_attention.dense.weight ...\n",
      "\t=> processing layers.4.post_attention_norm.weight ...\n",
      "\t=> processing layers.4.mlp.dense_h_to_4h.weight ...\n",
      "\t=> processing layers.4.mlp.dense_4h_to_h.weight ...\n",
      "\t=> processing layers.5.input_norm.weight ...\n",
      "\t=> processing layers.5.self_attention.query_key_value.weight ...\n",
      "\t=> processing layers.5.self_attention.dense.weight ...\n",
      "\t=> processing layers.5.post_attention_norm.weight ...\n",
      "\t=> processing layers.5.mlp.dense_h_to_4h.weight ...\n",
      "\t=> processing layers.5.mlp.dense_4h_to_h.weight ...\n",
      "\t=> processing layers.6.input_norm.weight ...\n",
      "\t=> processing layers.6.self_attention.query_key_value.weight ...\n",
      "\t=> processing layers.6.self_attention.dense.weight ...\n",
      "\t=> processing layers.6.post_attention_norm.weight ...\n",
      "\t=> processing layers.6.mlp.dense_h_to_4h.weight ...\n",
      "\t=> processing layers.6.mlp.dense_4h_to_h.weight ...\n",
      "\t=> processing layers.7.input_norm.weight ...\n",
      "\t=> processing layers.7.self_attention.query_key_value.weight ...\n",
      "\t=> processing layers.7.self_attention.dense.weight ...\n",
      "\t=> processing layers.7.post_attention_norm.weight ...\n",
      "\t=> processing layers.7.mlp.dense_h_to_4h.weight ...\n",
      "\t=> processing layers.7.mlp.dense_4h_to_h.weight ...\n",
      "\t=> processing layers.8.input_norm.weight ...\n",
      "\t=> processing layers.8.self_attention.query_key_value.weight ...\n",
      "\t=> processing layers.8.self_attention.dense.weight ...\n",
      "\t=> processing layers.8.post_attention_norm.weight ...\n",
      "\t=> processing layers.8.mlp.dense_h_to_4h.weight ...\n",
      "\t=> processing layers.8.mlp.dense_4h_to_h.weight ...\n",
      "\t=> processing layers.9.input_norm.weight ...\n",
      "\t=> processing layers.9.self_attention.query_key_value.weight ...\n",
      "\t=> processing layers.9.self_attention.dense.weight ...\n",
      "\t=> processing layers.9.post_attention_norm.weight ...\n",
      "\t=> processing layers.9.mlp.dense_h_to_4h.weight ...\n",
      "\t=> processing layers.9.mlp.dense_4h_to_h.weight ...\n",
      "\t=> processing layers.10.input_norm.weight ...\n",
      "\t=> processing layers.10.self_attention.query_key_value.weight ...\n",
      "\t=> processing layers.10.self_attention.dense.weight ...\n",
      "\t=> processing layers.10.post_attention_norm.weight ...\n",
      "\t=> processing layers.10.mlp.dense_h_to_4h.weight ...\n",
      "\t=> processing layers.10.mlp.dense_4h_to_h.weight ...\n",
      "\t=> processing layers.11.input_norm.weight ...\n",
      "\t=> processing layers.11.self_attention.query_key_value.weight ...\n",
      "\t=> processing layers.11.self_attention.dense.weight ...\n",
      "\t=> processing layers.11.post_attention_norm.weight ...\n",
      "\t=> processing layers.11.mlp.dense_h_to_4h.weight ...\n",
      "\t=> processing layers.11.mlp.dense_4h_to_h.weight ...\n",
      "\t=> processing layers.12.input_norm.weight ...\n",
      "\t=> processing layers.12.self_attention.query_key_value.weight ...\n",
      "\t=> processing layers.12.self_attention.dense.weight ...\n",
      "\t=> processing layers.12.post_attention_norm.weight ...\n",
      "\t=> processing layers.12.mlp.dense_h_to_4h.weight ...\n",
      "\t=> processing layers.12.mlp.dense_4h_to_h.weight ...\n",
      "\t=> processing layers.13.input_norm.weight ...\n",
      "\t=> processing layers.13.self_attention.query_key_value.weight ...\n",
      "\t=> processing layers.13.self_attention.dense.weight ...\n",
      "\t=> processing layers.13.post_attention_norm.weight ...\n",
      "\t=> processing layers.13.mlp.dense_h_to_4h.weight ...\n",
      "\t=> processing layers.13.mlp.dense_4h_to_h.weight ...\n",
      "\t=> processing layers.14.input_norm.weight ...\n",
      "\t=> processing layers.14.self_attention.query_key_value.weight ...\n",
      "\t=> processing layers.14.self_attention.dense.weight ...\n",
      "\t=> processing layers.14.post_attention_norm.weight ...\n",
      "\t=> processing layers.14.mlp.dense_h_to_4h.weight ...\n",
      "\t=> processing layers.14.mlp.dense_4h_to_h.weight ...\n",
      "\t=> processing layers.15.input_norm.weight ...\n",
      "\t=> processing layers.15.self_attention.query_key_value.weight ...\n",
      "\t=> processing layers.15.self_attention.dense.weight ...\n",
      "\t=> processing layers.15.post_attention_norm.weight ...\n",
      "\t=> processing layers.15.mlp.dense_h_to_4h.weight ...\n",
      "\t=> processing layers.15.mlp.dense_4h_to_h.weight ...\n",
      "\t=> processing layers.16.input_norm.weight ...\n",
      "\t=> processing layers.16.self_attention.query_key_value.weight ...\n",
      "\t=> processing layers.16.self_attention.dense.weight ...\n",
      "\t=> processing layers.16.post_attention_norm.weight ...\n",
      "\t=> processing layers.16.mlp.dense_h_to_4h.weight ...\n",
      "\t=> processing layers.16.mlp.dense_4h_to_h.weight ...\n",
      "\t=> processing layers.17.input_norm.weight ...\n",
      "\t=> processing layers.17.self_attention.query_key_value.weight ...\n",
      "\t=> processing layers.17.self_attention.dense.weight ...\n",
      "\t=> processing layers.17.post_attention_norm.weight ...\n",
      "\t=> processing layers.17.mlp.dense_h_to_4h.weight ...\n",
      "\t=> processing layers.17.mlp.dense_4h_to_h.weight ...\n",
      "\t=> processing layers.18.input_norm.weight ...\n",
      "\t=> processing layers.18.self_attention.query_key_value.weight ...\n",
      "\t=> processing layers.18.self_attention.dense.weight ...\n",
      "\t=> processing layers.18.post_attention_norm.weight ...\n",
      "\t=> processing layers.18.mlp.dense_h_to_4h.weight ...\n",
      "\t=> processing layers.18.mlp.dense_4h_to_h.weight ...\n",
      "\t=> processing layers.19.input_norm.weight ...\n",
      "\t=> processing layers.19.self_attention.query_key_value.weight ...\n",
      "\t=> processing layers.19.self_attention.dense.weight ...\n",
      "\t=> processing layers.19.post_attention_norm.weight ...\n",
      "\t=> processing layers.19.mlp.dense_h_to_4h.weight ...\n",
      "\t=> processing layers.19.mlp.dense_4h_to_h.weight ...\n",
      "\t=> processing final_norm.weight ...\n",
      "=> layer regex match failed [final_norm.weight] , skip ...\n",
      "=> converting final norm ...\n",
      "=> converting lm_head ...\n",
      "=> convertion from Megatron-LM to Transformers is done!\n",
      "# model.embed_tokens.weight                        : torch.Size([32000, 5120])\n",
      "# model.layers.0.input_layernorm.weight            : torch.Size([5120])\n",
      "# model.layers.0.self_attn.q_proj.weight           : torch.Size([5120, 5120])\n",
      "# model.layers.0.self_attn.k_proj.weight           : torch.Size([5120, 5120])\n",
      "# model.layers.0.self_attn.v_proj.weight           : torch.Size([5120, 5120])\n",
      "# model.layers.0.self_attn.o_proj.weight           : torch.Size([5120, 5120])\n",
      "# model.layers.0.post_attention_layernorm.weight   : torch.Size([5120])\n",
      "# model.layers.0.mlp.gate_proj.weight              : torch.Size([13824, 5120])\n",
      "# model.layers.0.mlp.up_proj.weight                : torch.Size([13824, 5120])\n",
      "# model.layers.0.mlp.down_proj.weight              : torch.Size([5120, 13824])\n",
      "# model.layers.1.input_layernorm.weight            : torch.Size([5120])\n",
      "# model.layers.1.self_attn.q_proj.weight           : torch.Size([5120, 5120])\n",
      "# model.layers.1.self_attn.k_proj.weight           : torch.Size([5120, 5120])\n",
      "# model.layers.1.self_attn.v_proj.weight           : torch.Size([5120, 5120])\n",
      "# model.layers.1.self_attn.o_proj.weight           : torch.Size([5120, 5120])\n",
      "# model.layers.1.post_attention_layernorm.weight   : torch.Size([5120])\n",
      "# model.layers.1.mlp.gate_proj.weight              : torch.Size([13824, 5120])\n",
      "# model.layers.1.mlp.up_proj.weight                : torch.Size([13824, 5120])\n",
      "# model.layers.1.mlp.down_proj.weight              : torch.Size([5120, 13824])\n",
      "# model.layers.2.input_layernorm.weight            : torch.Size([5120])\n",
      "# model.layers.2.self_attn.q_proj.weight           : torch.Size([5120, 5120])\n",
      "# model.layers.2.self_attn.k_proj.weight           : torch.Size([5120, 5120])\n",
      "# model.layers.2.self_attn.v_proj.weight           : torch.Size([5120, 5120])\n",
      "# model.layers.2.self_attn.o_proj.weight           : torch.Size([5120, 5120])\n",
      "# model.layers.2.post_attention_layernorm.weight   : torch.Size([5120])\n",
      "# model.layers.2.mlp.gate_proj.weight              : torch.Size([13824, 5120])\n",
      "# model.layers.2.mlp.up_proj.weight                : torch.Size([13824, 5120])\n",
      "# model.layers.2.mlp.down_proj.weight              : torch.Size([5120, 13824])\n",
      "# model.layers.3.input_layernorm.weight            : torch.Size([5120])\n",
      "# model.layers.3.self_attn.q_proj.weight           : torch.Size([5120, 5120])\n",
      "# model.layers.3.self_attn.k_proj.weight           : torch.Size([5120, 5120])\n",
      "# model.layers.3.self_attn.v_proj.weight           : torch.Size([5120, 5120])\n",
      "# model.layers.3.self_attn.o_proj.weight           : torch.Size([5120, 5120])\n",
      "# model.layers.3.post_attention_layernorm.weight   : torch.Size([5120])\n",
      "# model.layers.3.mlp.gate_proj.weight              : torch.Size([13824, 5120])\n",
      "# model.layers.3.mlp.up_proj.weight                : torch.Size([13824, 5120])\n",
      "# model.layers.3.mlp.down_proj.weight              : torch.Size([5120, 13824])\n",
      "# model.layers.4.input_layernorm.weight            : torch.Size([5120])\n",
      "# model.layers.4.self_attn.q_proj.weight           : torch.Size([5120, 5120])\n",
      "# model.layers.4.self_attn.k_proj.weight           : torch.Size([5120, 5120])\n",
      "# model.layers.4.self_attn.v_proj.weight           : torch.Size([5120, 5120])\n",
      "# model.layers.4.self_attn.o_proj.weight           : torch.Size([5120, 5120])\n",
      "# model.layers.4.post_attention_layernorm.weight   : torch.Size([5120])\n",
      "# model.layers.4.mlp.gate_proj.weight              : torch.Size([13824, 5120])\n",
      "# model.layers.4.mlp.up_proj.weight                : torch.Size([13824, 5120])\n",
      "# model.layers.4.mlp.down_proj.weight              : torch.Size([5120, 13824])\n",
      "# model.layers.5.input_layernorm.weight            : torch.Size([5120])\n",
      "# model.layers.5.self_attn.q_proj.weight           : torch.Size([5120, 5120])\n",
      "# model.layers.5.self_attn.k_proj.weight           : torch.Size([5120, 5120])\n",
      "# model.layers.5.self_attn.v_proj.weight           : torch.Size([5120, 5120])\n",
      "# model.layers.5.self_attn.o_proj.weight           : torch.Size([5120, 5120])\n",
      "# model.layers.5.post_attention_layernorm.weight   : torch.Size([5120])\n",
      "# model.layers.5.mlp.gate_proj.weight              : torch.Size([13824, 5120])\n",
      "# model.layers.5.mlp.up_proj.weight                : torch.Size([13824, 5120])\n",
      "# model.layers.5.mlp.down_proj.weight              : torch.Size([5120, 13824])\n",
      "# model.layers.6.input_layernorm.weight            : torch.Size([5120])\n",
      "# model.layers.6.self_attn.q_proj.weight           : torch.Size([5120, 5120])\n",
      "# model.layers.6.self_attn.k_proj.weight           : torch.Size([5120, 5120])\n",
      "# model.layers.6.self_attn.v_proj.weight           : torch.Size([5120, 5120])\n",
      "# model.layers.6.self_attn.o_proj.weight           : torch.Size([5120, 5120])\n",
      "# model.layers.6.post_attention_layernorm.weight   : torch.Size([5120])\n",
      "# model.layers.6.mlp.gate_proj.weight              : torch.Size([13824, 5120])\n",
      "# model.layers.6.mlp.up_proj.weight                : torch.Size([13824, 5120])\n",
      "# model.layers.6.mlp.down_proj.weight              : torch.Size([5120, 13824])\n",
      "# model.layers.7.input_layernorm.weight            : torch.Size([5120])\n",
      "# model.layers.7.self_attn.q_proj.weight           : torch.Size([5120, 5120])\n",
      "# model.layers.7.self_attn.k_proj.weight           : torch.Size([5120, 5120])\n",
      "# model.layers.7.self_attn.v_proj.weight           : torch.Size([5120, 5120])\n",
      "# model.layers.7.self_attn.o_proj.weight           : torch.Size([5120, 5120])\n",
      "# model.layers.7.post_attention_layernorm.weight   : torch.Size([5120])\n",
      "# model.layers.7.mlp.gate_proj.weight              : torch.Size([13824, 5120])\n",
      "# model.layers.7.mlp.up_proj.weight                : torch.Size([13824, 5120])\n",
      "# model.layers.7.mlp.down_proj.weight              : torch.Size([5120, 13824])\n",
      "# model.layers.8.input_layernorm.weight            : torch.Size([5120])\n",
      "# model.layers.8.self_attn.q_proj.weight           : torch.Size([5120, 5120])\n",
      "# model.layers.8.self_attn.k_proj.weight           : torch.Size([5120, 5120])\n",
      "# model.layers.8.self_attn.v_proj.weight           : torch.Size([5120, 5120])\n",
      "# model.layers.8.self_attn.o_proj.weight           : torch.Size([5120, 5120])\n",
      "# model.layers.8.post_attention_layernorm.weight   : torch.Size([5120])\n",
      "# model.layers.8.mlp.gate_proj.weight              : torch.Size([13824, 5120])\n",
      "# model.layers.8.mlp.up_proj.weight                : torch.Size([13824, 5120])\n",
      "# model.layers.8.mlp.down_proj.weight              : torch.Size([5120, 13824])\n",
      "# model.layers.9.input_layernorm.weight            : torch.Size([5120])\n",
      "# model.layers.9.self_attn.q_proj.weight           : torch.Size([5120, 5120])\n",
      "# model.layers.9.self_attn.k_proj.weight           : torch.Size([5120, 5120])\n",
      "# model.layers.9.self_attn.v_proj.weight           : torch.Size([5120, 5120])\n",
      "# model.layers.9.self_attn.o_proj.weight           : torch.Size([5120, 5120])\n",
      "# model.layers.9.post_attention_layernorm.weight   : torch.Size([5120])\n",
      "# model.layers.9.mlp.gate_proj.weight              : torch.Size([13824, 5120])\n",
      "# model.layers.9.mlp.up_proj.weight                : torch.Size([13824, 5120])\n",
      "# model.layers.9.mlp.down_proj.weight              : torch.Size([5120, 13824])\n",
      "# model.layers.10.input_layernorm.weight           : torch.Size([5120])\n",
      "# model.layers.10.self_attn.q_proj.weight          : torch.Size([5120, 5120])\n",
      "# model.layers.10.self_attn.k_proj.weight          : torch.Size([5120, 5120])\n",
      "# model.layers.10.self_attn.v_proj.weight          : torch.Size([5120, 5120])\n",
      "# model.layers.10.self_attn.o_proj.weight          : torch.Size([5120, 5120])\n",
      "# model.layers.10.post_attention_layernorm.weight  : torch.Size([5120])\n",
      "# model.layers.10.mlp.gate_proj.weight             : torch.Size([13824, 5120])\n",
      "# model.layers.10.mlp.up_proj.weight               : torch.Size([13824, 5120])\n",
      "# model.layers.10.mlp.down_proj.weight             : torch.Size([5120, 13824])\n",
      "# model.layers.11.input_layernorm.weight           : torch.Size([5120])\n",
      "# model.layers.11.self_attn.q_proj.weight          : torch.Size([5120, 5120])\n",
      "# model.layers.11.self_attn.k_proj.weight          : torch.Size([5120, 5120])\n",
      "# model.layers.11.self_attn.v_proj.weight          : torch.Size([5120, 5120])\n",
      "# model.layers.11.self_attn.o_proj.weight          : torch.Size([5120, 5120])\n",
      "# model.layers.11.post_attention_layernorm.weight  : torch.Size([5120])\n",
      "# model.layers.11.mlp.gate_proj.weight             : torch.Size([13824, 5120])\n",
      "# model.layers.11.mlp.up_proj.weight               : torch.Size([13824, 5120])\n",
      "# model.layers.11.mlp.down_proj.weight             : torch.Size([5120, 13824])\n",
      "# model.layers.12.input_layernorm.weight           : torch.Size([5120])\n",
      "# model.layers.12.self_attn.q_proj.weight          : torch.Size([5120, 5120])\n",
      "# model.layers.12.self_attn.k_proj.weight          : torch.Size([5120, 5120])\n",
      "# model.layers.12.self_attn.v_proj.weight          : torch.Size([5120, 5120])\n",
      "# model.layers.12.self_attn.o_proj.weight          : torch.Size([5120, 5120])\n",
      "# model.layers.12.post_attention_layernorm.weight  : torch.Size([5120])\n",
      "# model.layers.12.mlp.gate_proj.weight             : torch.Size([13824, 5120])\n",
      "# model.layers.12.mlp.up_proj.weight               : torch.Size([13824, 5120])\n",
      "# model.layers.12.mlp.down_proj.weight             : torch.Size([5120, 13824])\n",
      "# model.layers.13.input_layernorm.weight           : torch.Size([5120])\n",
      "# model.layers.13.self_attn.q_proj.weight          : torch.Size([5120, 5120])\n",
      "# model.layers.13.self_attn.k_proj.weight          : torch.Size([5120, 5120])\n",
      "# model.layers.13.self_attn.v_proj.weight          : torch.Size([5120, 5120])\n",
      "# model.layers.13.self_attn.o_proj.weight          : torch.Size([5120, 5120])\n",
      "# model.layers.13.post_attention_layernorm.weight  : torch.Size([5120])\n",
      "# model.layers.13.mlp.gate_proj.weight             : torch.Size([13824, 5120])\n",
      "# model.layers.13.mlp.up_proj.weight               : torch.Size([13824, 5120])\n",
      "# model.layers.13.mlp.down_proj.weight             : torch.Size([5120, 13824])\n",
      "# model.layers.14.input_layernorm.weight           : torch.Size([5120])\n",
      "# model.layers.14.self_attn.q_proj.weight          : torch.Size([5120, 5120])\n",
      "# model.layers.14.self_attn.k_proj.weight          : torch.Size([5120, 5120])\n",
      "# model.layers.14.self_attn.v_proj.weight          : torch.Size([5120, 5120])\n",
      "# model.layers.14.self_attn.o_proj.weight          : torch.Size([5120, 5120])\n",
      "# model.layers.14.post_attention_layernorm.weight  : torch.Size([5120])\n",
      "# model.layers.14.mlp.gate_proj.weight             : torch.Size([13824, 5120])\n",
      "# model.layers.14.mlp.up_proj.weight               : torch.Size([13824, 5120])\n",
      "# model.layers.14.mlp.down_proj.weight             : torch.Size([5120, 13824])\n",
      "# model.layers.15.input_layernorm.weight           : torch.Size([5120])\n",
      "# model.layers.15.self_attn.q_proj.weight          : torch.Size([5120, 5120])\n",
      "# model.layers.15.self_attn.k_proj.weight          : torch.Size([5120, 5120])\n",
      "# model.layers.15.self_attn.v_proj.weight          : torch.Size([5120, 5120])\n",
      "# model.layers.15.self_attn.o_proj.weight          : torch.Size([5120, 5120])\n",
      "# model.layers.15.post_attention_layernorm.weight  : torch.Size([5120])\n",
      "# model.layers.15.mlp.gate_proj.weight             : torch.Size([13824, 5120])\n",
      "# model.layers.15.mlp.up_proj.weight               : torch.Size([13824, 5120])\n",
      "# model.layers.15.mlp.down_proj.weight             : torch.Size([5120, 13824])\n",
      "# model.layers.16.input_layernorm.weight           : torch.Size([5120])\n",
      "# model.layers.16.self_attn.q_proj.weight          : torch.Size([5120, 5120])\n",
      "# model.layers.16.self_attn.k_proj.weight          : torch.Size([5120, 5120])\n",
      "# model.layers.16.self_attn.v_proj.weight          : torch.Size([5120, 5120])\n",
      "# model.layers.16.self_attn.o_proj.weight          : torch.Size([5120, 5120])\n",
      "# model.layers.16.post_attention_layernorm.weight  : torch.Size([5120])\n",
      "# model.layers.16.mlp.gate_proj.weight             : torch.Size([13824, 5120])\n",
      "# model.layers.16.mlp.up_proj.weight               : torch.Size([13824, 5120])\n",
      "# model.layers.16.mlp.down_proj.weight             : torch.Size([5120, 13824])\n",
      "# model.layers.17.input_layernorm.weight           : torch.Size([5120])\n",
      "# model.layers.17.self_attn.q_proj.weight          : torch.Size([5120, 5120])\n",
      "# model.layers.17.self_attn.k_proj.weight          : torch.Size([5120, 5120])\n",
      "# model.layers.17.self_attn.v_proj.weight          : torch.Size([5120, 5120])\n",
      "# model.layers.17.self_attn.o_proj.weight          : torch.Size([5120, 5120])\n",
      "# model.layers.17.post_attention_layernorm.weight  : torch.Size([5120])\n",
      "# model.layers.17.mlp.gate_proj.weight             : torch.Size([13824, 5120])\n",
      "# model.layers.17.mlp.up_proj.weight               : torch.Size([13824, 5120])\n",
      "# model.layers.17.mlp.down_proj.weight             : torch.Size([5120, 13824])\n",
      "# model.layers.18.input_layernorm.weight           : torch.Size([5120])\n",
      "# model.layers.18.self_attn.q_proj.weight          : torch.Size([5120, 5120])\n",
      "# model.layers.18.self_attn.k_proj.weight          : torch.Size([5120, 5120])\n",
      "# model.layers.18.self_attn.v_proj.weight          : torch.Size([5120, 5120])\n",
      "# model.layers.18.self_attn.o_proj.weight          : torch.Size([5120, 5120])\n",
      "# model.layers.18.post_attention_layernorm.weight  : torch.Size([5120])\n",
      "# model.layers.18.mlp.gate_proj.weight             : torch.Size([13824, 5120])\n",
      "# model.layers.18.mlp.up_proj.weight               : torch.Size([13824, 5120])\n",
      "# model.layers.18.mlp.down_proj.weight             : torch.Size([5120, 13824])\n",
      "# model.layers.19.input_layernorm.weight           : torch.Size([5120])\n",
      "# model.layers.19.self_attn.q_proj.weight          : torch.Size([5120, 5120])\n",
      "# model.layers.19.self_attn.k_proj.weight          : torch.Size([5120, 5120])\n",
      "# model.layers.19.self_attn.v_proj.weight          : torch.Size([5120, 5120])\n",
      "# model.layers.19.self_attn.o_proj.weight          : torch.Size([5120, 5120])\n",
      "# model.layers.19.post_attention_layernorm.weight  : torch.Size([5120])\n",
      "# model.layers.19.mlp.gate_proj.weight             : torch.Size([13824, 5120])\n",
      "# model.layers.19.mlp.up_proj.weight               : torch.Size([13824, 5120])\n",
      "# model.layers.19.mlp.down_proj.weight             : torch.Size([5120, 13824])\n",
      "# model.layers.20.input_layernorm.weight           : torch.Size([5120])\n",
      "# model.layers.20.self_attn.q_proj.weight          : torch.Size([5120, 5120])\n",
      "# model.layers.20.self_attn.k_proj.weight          : torch.Size([5120, 5120])\n",
      "# model.layers.20.self_attn.v_proj.weight          : torch.Size([5120, 5120])\n",
      "# model.layers.20.self_attn.o_proj.weight          : torch.Size([5120, 5120])\n",
      "# model.layers.20.post_attention_layernorm.weight  : torch.Size([5120])\n",
      "# model.layers.20.mlp.gate_proj.weight             : torch.Size([13824, 5120])\n",
      "# model.layers.20.mlp.up_proj.weight               : torch.Size([13824, 5120])\n",
      "# model.layers.20.mlp.down_proj.weight             : torch.Size([5120, 13824])\n",
      "# model.layers.21.input_layernorm.weight           : torch.Size([5120])\n",
      "# model.layers.21.self_attn.q_proj.weight          : torch.Size([5120, 5120])\n",
      "# model.layers.21.self_attn.k_proj.weight          : torch.Size([5120, 5120])\n",
      "# model.layers.21.self_attn.v_proj.weight          : torch.Size([5120, 5120])\n",
      "# model.layers.21.self_attn.o_proj.weight          : torch.Size([5120, 5120])\n",
      "# model.layers.21.post_attention_layernorm.weight  : torch.Size([5120])\n",
      "# model.layers.21.mlp.gate_proj.weight             : torch.Size([13824, 5120])\n",
      "# model.layers.21.mlp.up_proj.weight               : torch.Size([13824, 5120])\n",
      "# model.layers.21.mlp.down_proj.weight             : torch.Size([5120, 13824])\n",
      "# model.layers.22.input_layernorm.weight           : torch.Size([5120])\n",
      "# model.layers.22.self_attn.q_proj.weight          : torch.Size([5120, 5120])\n",
      "# model.layers.22.self_attn.k_proj.weight          : torch.Size([5120, 5120])\n",
      "# model.layers.22.self_attn.v_proj.weight          : torch.Size([5120, 5120])\n",
      "# model.layers.22.self_attn.o_proj.weight          : torch.Size([5120, 5120])\n",
      "# model.layers.22.post_attention_layernorm.weight  : torch.Size([5120])\n",
      "# model.layers.22.mlp.gate_proj.weight             : torch.Size([13824, 5120])\n",
      "# model.layers.22.mlp.up_proj.weight               : torch.Size([13824, 5120])\n",
      "# model.layers.22.mlp.down_proj.weight             : torch.Size([5120, 13824])\n",
      "# model.layers.23.input_layernorm.weight           : torch.Size([5120])\n",
      "# model.layers.23.self_attn.q_proj.weight          : torch.Size([5120, 5120])\n",
      "# model.layers.23.self_attn.k_proj.weight          : torch.Size([5120, 5120])\n",
      "# model.layers.23.self_attn.v_proj.weight          : torch.Size([5120, 5120])\n",
      "# model.layers.23.self_attn.o_proj.weight          : torch.Size([5120, 5120])\n",
      "# model.layers.23.post_attention_layernorm.weight  : torch.Size([5120])\n",
      "# model.layers.23.mlp.gate_proj.weight             : torch.Size([13824, 5120])\n",
      "# model.layers.23.mlp.up_proj.weight               : torch.Size([13824, 5120])\n",
      "# model.layers.23.mlp.down_proj.weight             : torch.Size([5120, 13824])\n",
      "# model.layers.24.input_layernorm.weight           : torch.Size([5120])\n",
      "# model.layers.24.self_attn.q_proj.weight          : torch.Size([5120, 5120])\n",
      "# model.layers.24.self_attn.k_proj.weight          : torch.Size([5120, 5120])\n",
      "# model.layers.24.self_attn.v_proj.weight          : torch.Size([5120, 5120])\n",
      "# model.layers.24.self_attn.o_proj.weight          : torch.Size([5120, 5120])\n",
      "# model.layers.24.post_attention_layernorm.weight  : torch.Size([5120])\n",
      "# model.layers.24.mlp.gate_proj.weight             : torch.Size([13824, 5120])\n",
      "# model.layers.24.mlp.up_proj.weight               : torch.Size([13824, 5120])\n",
      "# model.layers.24.mlp.down_proj.weight             : torch.Size([5120, 13824])\n",
      "# model.layers.25.input_layernorm.weight           : torch.Size([5120])\n",
      "# model.layers.25.self_attn.q_proj.weight          : torch.Size([5120, 5120])\n",
      "# model.layers.25.self_attn.k_proj.weight          : torch.Size([5120, 5120])\n",
      "# model.layers.25.self_attn.v_proj.weight          : torch.Size([5120, 5120])\n",
      "# model.layers.25.self_attn.o_proj.weight          : torch.Size([5120, 5120])\n",
      "# model.layers.25.post_attention_layernorm.weight  : torch.Size([5120])\n",
      "# model.layers.25.mlp.gate_proj.weight             : torch.Size([13824, 5120])\n",
      "# model.layers.25.mlp.up_proj.weight               : torch.Size([13824, 5120])\n",
      "# model.layers.25.mlp.down_proj.weight             : torch.Size([5120, 13824])\n",
      "# model.layers.26.input_layernorm.weight           : torch.Size([5120])\n",
      "# model.layers.26.self_attn.q_proj.weight          : torch.Size([5120, 5120])\n",
      "# model.layers.26.self_attn.k_proj.weight          : torch.Size([5120, 5120])\n",
      "# model.layers.26.self_attn.v_proj.weight          : torch.Size([5120, 5120])\n",
      "# model.layers.26.self_attn.o_proj.weight          : torch.Size([5120, 5120])\n",
      "# model.layers.26.post_attention_layernorm.weight  : torch.Size([5120])\n",
      "# model.layers.26.mlp.gate_proj.weight             : torch.Size([13824, 5120])\n",
      "# model.layers.26.mlp.up_proj.weight               : torch.Size([13824, 5120])\n",
      "# model.layers.26.mlp.down_proj.weight             : torch.Size([5120, 13824])\n",
      "# model.layers.27.input_layernorm.weight           : torch.Size([5120])\n",
      "# model.layers.27.self_attn.q_proj.weight          : torch.Size([5120, 5120])\n",
      "# model.layers.27.self_attn.k_proj.weight          : torch.Size([5120, 5120])\n",
      "# model.layers.27.self_attn.v_proj.weight          : torch.Size([5120, 5120])\n",
      "# model.layers.27.self_attn.o_proj.weight          : torch.Size([5120, 5120])\n",
      "# model.layers.27.post_attention_layernorm.weight  : torch.Size([5120])\n",
      "# model.layers.27.mlp.gate_proj.weight             : torch.Size([13824, 5120])\n",
      "# model.layers.27.mlp.up_proj.weight               : torch.Size([13824, 5120])\n",
      "# model.layers.27.mlp.down_proj.weight             : torch.Size([5120, 13824])\n",
      "# model.layers.28.input_layernorm.weight           : torch.Size([5120])\n",
      "# model.layers.28.self_attn.q_proj.weight          : torch.Size([5120, 5120])\n",
      "# model.layers.28.self_attn.k_proj.weight          : torch.Size([5120, 5120])\n",
      "# model.layers.28.self_attn.v_proj.weight          : torch.Size([5120, 5120])\n",
      "# model.layers.28.self_attn.o_proj.weight          : torch.Size([5120, 5120])\n",
      "# model.layers.28.post_attention_layernorm.weight  : torch.Size([5120])\n",
      "# model.layers.28.mlp.gate_proj.weight             : torch.Size([13824, 5120])\n",
      "# model.layers.28.mlp.up_proj.weight               : torch.Size([13824, 5120])\n",
      "# model.layers.28.mlp.down_proj.weight             : torch.Size([5120, 13824])\n",
      "# model.layers.29.input_layernorm.weight           : torch.Size([5120])\n",
      "# model.layers.29.self_attn.q_proj.weight          : torch.Size([5120, 5120])\n",
      "# model.layers.29.self_attn.k_proj.weight          : torch.Size([5120, 5120])\n",
      "# model.layers.29.self_attn.v_proj.weight          : torch.Size([5120, 5120])\n",
      "# model.layers.29.self_attn.o_proj.weight          : torch.Size([5120, 5120])\n",
      "# model.layers.29.post_attention_layernorm.weight  : torch.Size([5120])\n",
      "# model.layers.29.mlp.gate_proj.weight             : torch.Size([13824, 5120])\n",
      "# model.layers.29.mlp.up_proj.weight               : torch.Size([13824, 5120])\n",
      "# model.layers.29.mlp.down_proj.weight             : torch.Size([5120, 13824])\n",
      "# model.layers.30.input_layernorm.weight           : torch.Size([5120])\n",
      "# model.layers.30.self_attn.q_proj.weight          : torch.Size([5120, 5120])\n",
      "# model.layers.30.self_attn.k_proj.weight          : torch.Size([5120, 5120])\n",
      "# model.layers.30.self_attn.v_proj.weight          : torch.Size([5120, 5120])\n",
      "# model.layers.30.self_attn.o_proj.weight          : torch.Size([5120, 5120])\n",
      "# model.layers.30.post_attention_layernorm.weight  : torch.Size([5120])\n",
      "# model.layers.30.mlp.gate_proj.weight             : torch.Size([13824, 5120])\n",
      "# model.layers.30.mlp.up_proj.weight               : torch.Size([13824, 5120])\n",
      "# model.layers.30.mlp.down_proj.weight             : torch.Size([5120, 13824])\n",
      "# model.layers.31.input_layernorm.weight           : torch.Size([5120])\n",
      "# model.layers.31.self_attn.q_proj.weight          : torch.Size([5120, 5120])\n",
      "# model.layers.31.self_attn.k_proj.weight          : torch.Size([5120, 5120])\n",
      "# model.layers.31.self_attn.v_proj.weight          : torch.Size([5120, 5120])\n",
      "# model.layers.31.self_attn.o_proj.weight          : torch.Size([5120, 5120])\n",
      "# model.layers.31.post_attention_layernorm.weight  : torch.Size([5120])\n",
      "# model.layers.31.mlp.gate_proj.weight             : torch.Size([13824, 5120])\n",
      "# model.layers.31.mlp.up_proj.weight               : torch.Size([13824, 5120])\n",
      "# model.layers.31.mlp.down_proj.weight             : torch.Size([5120, 13824])\n",
      "# model.layers.32.input_layernorm.weight           : torch.Size([5120])\n",
      "# model.layers.32.self_attn.q_proj.weight          : torch.Size([5120, 5120])\n",
      "# model.layers.32.self_attn.k_proj.weight          : torch.Size([5120, 5120])\n",
      "# model.layers.32.self_attn.v_proj.weight          : torch.Size([5120, 5120])\n",
      "# model.layers.32.self_attn.o_proj.weight          : torch.Size([5120, 5120])\n",
      "# model.layers.32.post_attention_layernorm.weight  : torch.Size([5120])\n",
      "# model.layers.32.mlp.gate_proj.weight             : torch.Size([13824, 5120])\n",
      "# model.layers.32.mlp.up_proj.weight               : torch.Size([13824, 5120])\n",
      "# model.layers.32.mlp.down_proj.weight             : torch.Size([5120, 13824])\n",
      "# model.layers.33.input_layernorm.weight           : torch.Size([5120])\n",
      "# model.layers.33.self_attn.q_proj.weight          : torch.Size([5120, 5120])\n",
      "# model.layers.33.self_attn.k_proj.weight          : torch.Size([5120, 5120])\n",
      "# model.layers.33.self_attn.v_proj.weight          : torch.Size([5120, 5120])\n",
      "# model.layers.33.self_attn.o_proj.weight          : torch.Size([5120, 5120])\n",
      "# model.layers.33.post_attention_layernorm.weight  : torch.Size([5120])\n",
      "# model.layers.33.mlp.gate_proj.weight             : torch.Size([13824, 5120])\n",
      "# model.layers.33.mlp.up_proj.weight               : torch.Size([13824, 5120])\n",
      "# model.layers.33.mlp.down_proj.weight             : torch.Size([5120, 13824])\n",
      "# model.layers.34.input_layernorm.weight           : torch.Size([5120])\n",
      "# model.layers.34.self_attn.q_proj.weight          : torch.Size([5120, 5120])\n",
      "# model.layers.34.self_attn.k_proj.weight          : torch.Size([5120, 5120])\n",
      "# model.layers.34.self_attn.v_proj.weight          : torch.Size([5120, 5120])\n",
      "# model.layers.34.self_attn.o_proj.weight          : torch.Size([5120, 5120])\n",
      "# model.layers.34.post_attention_layernorm.weight  : torch.Size([5120])\n",
      "# model.layers.34.mlp.gate_proj.weight             : torch.Size([13824, 5120])\n",
      "# model.layers.34.mlp.up_proj.weight               : torch.Size([13824, 5120])\n",
      "# model.layers.34.mlp.down_proj.weight             : torch.Size([5120, 13824])\n",
      "# model.layers.35.input_layernorm.weight           : torch.Size([5120])\n",
      "# model.layers.35.self_attn.q_proj.weight          : torch.Size([5120, 5120])\n",
      "# model.layers.35.self_attn.k_proj.weight          : torch.Size([5120, 5120])\n",
      "# model.layers.35.self_attn.v_proj.weight          : torch.Size([5120, 5120])\n",
      "# model.layers.35.self_attn.o_proj.weight          : torch.Size([5120, 5120])\n",
      "# model.layers.35.post_attention_layernorm.weight  : torch.Size([5120])\n",
      "# model.layers.35.mlp.gate_proj.weight             : torch.Size([13824, 5120])\n",
      "# model.layers.35.mlp.up_proj.weight               : torch.Size([13824, 5120])\n",
      "# model.layers.35.mlp.down_proj.weight             : torch.Size([5120, 13824])\n",
      "# model.layers.36.input_layernorm.weight           : torch.Size([5120])\n",
      "# model.layers.36.self_attn.q_proj.weight          : torch.Size([5120, 5120])\n",
      "# model.layers.36.self_attn.k_proj.weight          : torch.Size([5120, 5120])\n",
      "# model.layers.36.self_attn.v_proj.weight          : torch.Size([5120, 5120])\n",
      "# model.layers.36.self_attn.o_proj.weight          : torch.Size([5120, 5120])\n",
      "# model.layers.36.post_attention_layernorm.weight  : torch.Size([5120])\n",
      "# model.layers.36.mlp.gate_proj.weight             : torch.Size([13824, 5120])\n",
      "# model.layers.36.mlp.up_proj.weight               : torch.Size([13824, 5120])\n",
      "# model.layers.36.mlp.down_proj.weight             : torch.Size([5120, 13824])\n",
      "# model.layers.37.input_layernorm.weight           : torch.Size([5120])\n",
      "# model.layers.37.self_attn.q_proj.weight          : torch.Size([5120, 5120])\n",
      "# model.layers.37.self_attn.k_proj.weight          : torch.Size([5120, 5120])\n",
      "# model.layers.37.self_attn.v_proj.weight          : torch.Size([5120, 5120])\n",
      "# model.layers.37.self_attn.o_proj.weight          : torch.Size([5120, 5120])\n",
      "# model.layers.37.post_attention_layernorm.weight  : torch.Size([5120])\n",
      "# model.layers.37.mlp.gate_proj.weight             : torch.Size([13824, 5120])\n",
      "# model.layers.37.mlp.up_proj.weight               : torch.Size([13824, 5120])\n",
      "# model.layers.37.mlp.down_proj.weight             : torch.Size([5120, 13824])\n",
      "# model.layers.38.input_layernorm.weight           : torch.Size([5120])\n",
      "# model.layers.38.self_attn.q_proj.weight          : torch.Size([5120, 5120])\n",
      "# model.layers.38.self_attn.k_proj.weight          : torch.Size([5120, 5120])\n",
      "# model.layers.38.self_attn.v_proj.weight          : torch.Size([5120, 5120])\n",
      "# model.layers.38.self_attn.o_proj.weight          : torch.Size([5120, 5120])\n",
      "# model.layers.38.post_attention_layernorm.weight  : torch.Size([5120])\n",
      "# model.layers.38.mlp.gate_proj.weight             : torch.Size([13824, 5120])\n",
      "# model.layers.38.mlp.up_proj.weight               : torch.Size([13824, 5120])\n",
      "# model.layers.38.mlp.down_proj.weight             : torch.Size([5120, 13824])\n",
      "# model.layers.39.input_layernorm.weight           : torch.Size([5120])\n",
      "# model.layers.39.self_attn.q_proj.weight          : torch.Size([5120, 5120])\n",
      "# model.layers.39.self_attn.k_proj.weight          : torch.Size([5120, 5120])\n",
      "# model.layers.39.self_attn.v_proj.weight          : torch.Size([5120, 5120])\n",
      "# model.layers.39.self_attn.o_proj.weight          : torch.Size([5120, 5120])\n",
      "# model.layers.39.post_attention_layernorm.weight  : torch.Size([5120])\n",
      "# model.layers.39.mlp.gate_proj.weight             : torch.Size([13824, 5120])\n",
      "# model.layers.39.mlp.up_proj.weight               : torch.Size([13824, 5120])\n",
      "# model.layers.39.mlp.down_proj.weight             : torch.Size([5120, 13824])\n",
      "# model.norm.weight                                : torch.Size([5120])\n",
      "# lm_head.weight                                   : torch.Size([32000, 5120])\n",
      "The model is bigger than the maximum size per checkpoint (10GB) and is going to be split in 3 checkpoint shards. You can find where each parameters has been saved in the index located at /cpfs/29ccba8f16c61395/data/user/liushan/projects/Megatron-LM-master/models/llama-hf/pytorch_model.bin.index.json.\n"
     ]
    }
   ],
   "source": [
    "unicorn.convert_checkpoint_from_megatron_to_transformers(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b7f383e-6d9f-4632-bcad-360c847caf8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config.json\t\t\t  pytorch_model-00003-of-00003.bin\n",
      "pytorch_model-00001-of-00003.bin  pytorch_model.bin.index.json\n",
      "pytorch_model-00002-of-00003.bin\n"
     ]
    }
   ],
   "source": [
    "target_path = os.path.join(MEGATRON_ROOT, \"models\", \"llama-hf\")\n",
    "!ls {target_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ce7ed8-24d0-4457-a783-ef50c3d51993",
   "metadata": {},
   "source": [
    "#### Compare model weights.\n",
    "* You can check the shell example `tools/unicorn/examples/llama/compare_hf_model.sh`.\n",
    "* The results will show the key with different content, if the value's dtype, shape or elements count.\n",
    "    * **\\*.rotary_emb.inv_freq** can ignore, pay attention to other keys.\n",
    "    * Empty results is okay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc7e8964-1aea-4ab7-aeda-de3cd568bb3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Comparing SRC[/cpfs/29ccba8f16c61395/data/user/liushan/projects/Megatron-LM-master/models/Llama-2-13b-hf] to DST[/cpfs/29ccba8f16c61395/data/user/liushan/projects/Megatron-LM-master/models/llama-hf] ...\n",
      "=> Only these keys in src_model: [/cpfs/29ccba8f16c61395/data/user/liushan/projects/Megatron-LM-master/models/Llama-2-13b-hf]: == {'model.layers.9.self_attn.rotary_emb.inv_freq', 'model.layers.33.self_attn.rotary_emb.inv_freq', 'model.layers.24.self_attn.rotary_emb.inv_freq', 'model.layers.36.self_attn.rotary_emb.inv_freq', 'model.layers.38.self_attn.rotary_emb.inv_freq', 'model.layers.6.self_attn.rotary_emb.inv_freq', 'model.layers.3.self_attn.rotary_emb.inv_freq', 'model.layers.1.self_attn.rotary_emb.inv_freq', 'model.layers.26.self_attn.rotary_emb.inv_freq', 'model.layers.14.self_attn.rotary_emb.inv_freq', 'model.layers.5.self_attn.rotary_emb.inv_freq', 'model.layers.22.self_attn.rotary_emb.inv_freq', 'model.layers.29.self_attn.rotary_emb.inv_freq', 'model.layers.2.self_attn.rotary_emb.inv_freq', 'model.layers.0.self_attn.rotary_emb.inv_freq', 'model.layers.37.self_attn.rotary_emb.inv_freq', 'model.layers.25.self_attn.rotary_emb.inv_freq', 'model.layers.13.self_attn.rotary_emb.inv_freq', 'model.layers.34.self_attn.rotary_emb.inv_freq', 'model.layers.27.self_attn.rotary_emb.inv_freq', 'model.layers.32.self_attn.rotary_emb.inv_freq', 'model.layers.7.self_attn.rotary_emb.inv_freq', 'model.layers.20.self_attn.rotary_emb.inv_freq', 'model.layers.4.self_attn.rotary_emb.inv_freq', 'model.layers.11.self_attn.rotary_emb.inv_freq', 'model.layers.16.self_attn.rotary_emb.inv_freq', 'model.layers.35.self_attn.rotary_emb.inv_freq', 'model.layers.23.self_attn.rotary_emb.inv_freq', 'model.layers.19.self_attn.rotary_emb.inv_freq', 'model.layers.10.self_attn.rotary_emb.inv_freq', 'model.layers.39.self_attn.rotary_emb.inv_freq', 'model.layers.18.self_attn.rotary_emb.inv_freq', 'model.layers.12.self_attn.rotary_emb.inv_freq', 'model.layers.28.self_attn.rotary_emb.inv_freq', 'model.layers.31.self_attn.rotary_emb.inv_freq', 'model.layers.8.self_attn.rotary_emb.inv_freq', 'model.layers.21.self_attn.rotary_emb.inv_freq', 'model.layers.17.self_attn.rotary_emb.inv_freq', 'model.layers.30.self_attn.rotary_emb.inv_freq', 'model.layers.15.self_attn.rotary_emb.inv_freq'}\n"
     ]
    }
   ],
   "source": [
    "sys.path.append(os.path.join(MEGATRON_ROOT, \"tests\", \"unicorn\"))\n",
    "from compare_hf_model import compare_state_dicts, load_hf_model\n",
    "\n",
    "src_state_dict = load_hf_model(os.path.join(MEGATRON_ROOT, \"models\", \"Llama-2-13b-hf\"))\n",
    "dst_state_dict = load_hf_model(os.path.join(MEGATRON_ROOT, \"models\", \"llama-hf\"))\n",
    "_ = compare_state_dicts(src_state_dict, dst_state_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
